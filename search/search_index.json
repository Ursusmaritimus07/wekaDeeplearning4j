{
    "docs": [
        {
            "location": "/",
            "text": "WekaDeeplearning4J: Deep Learning using Weka\n\n\n\nWekaDeeplearning4J is a deep learning package for the \nWeka\n workbench. It is developed to incorporate the modern techniques of deep learning into Weka. The backend is provided by the \nDeeplearning4J\n Java library. \n\n\nThe source code for this package is available on \nGitHub\n. The java-doc can be found \nhere\n.\n\n\nFunctionality\n\n\nAll functionality of this package is accessible via the Weka GUI, the commandline and programmatically in Java.\n\n\nThe following Neural Network Layers are available to build sophisticated architectures:\n\n\n\n\nConvolutionLayer\n: applying convolution, useful for images and text embeddings\n\n\nDenseLayer\n: all units are connected to all units of its parent layer\n\n\nSubsamplingLayer\n: subsample from groups of units of the parent layer by different strategies (average, maximum, etc.)\n\n\nBatchNormalization\n: applies the common batch normalization strategy on the activations of the parent layer\n\n\nLSTM\n: uses long short term memory approach\n\n\nGlobalPoolingLayer\n: apply pooling over time for RNNs and pooling for CNNs applied on sequences\n\n\nOutputLayer\n: generates classification / regression outputs\n\n\n\n\nFurther configurations can be found in the \nGetting Started\n and the \nExamples\n sections.",
            "title": "Home"
        },
        {
            "location": "/#wekadeeplearning4j-deep-learning-using-weka",
            "text": "WekaDeeplearning4J is a deep learning package for the  Weka  workbench. It is developed to incorporate the modern techniques of deep learning into Weka. The backend is provided by the  Deeplearning4J  Java library.   The source code for this package is available on  GitHub . The java-doc can be found  here .",
            "title": "WekaDeeplearning4J: Deep Learning using Weka"
        },
        {
            "location": "/#functionality",
            "text": "All functionality of this package is accessible via the Weka GUI, the commandline and programmatically in Java.  The following Neural Network Layers are available to build sophisticated architectures:   ConvolutionLayer : applying convolution, useful for images and text embeddings  DenseLayer : all units are connected to all units of its parent layer  SubsamplingLayer : subsample from groups of units of the parent layer by different strategies (average, maximum, etc.)  BatchNormalization : applies the common batch normalization strategy on the activations of the parent layer  LSTM : uses long short term memory approach  GlobalPoolingLayer : apply pooling over time for RNNs and pooling for CNNs applied on sequences  OutputLayer : generates classification / regression outputs   Further configurations can be found in the  Getting Started  and the  Examples  sections.",
            "title": "Functionality"
        },
        {
            "location": "/install/",
            "text": "Prerequisites\n\n\n\n\nWeka 3.8.0 or above (\nhere\n)\n\n\nWekaDeeplearning4j package 1.5.0 or above (\nhere\n)\n\n\n\n\nYou need to unzip the Weka zip file to a directory of your choice.\n\n\nCPU\n\n\nFor the package no further requisites are necessary.\n\n\nGPU\n\n\nThe GPU additions needs the CUDA 8.0, 9.0 or 9.1 backend with the appropriate cuDNN library to be installed on your system. Nvidia provides some good installation instructions for all platforms:\n\n\n\n\nLinux\n\n\nMac OS X\n\n\nWindows\n\n\n\n\nInstalling the Weka Package\n\n\nWeka packages can be easily installed either via the user interface as described \nhere\n, or simply via the commandline:\n\n\n$ java -cp <WEKA-JAR-PATH> weka.core.WekaPackageManager \\\n       -install-package <PACKAGE-ZIP>\n\n\n\n\nwhere \n<WEKA-JAR-PATH>\n must be replaced by the path pointing to the Weka jar file, and \n<PACKAGE-ZIP>\n is the wekaDeeplearning4j package zip file.\n\n\nYou can check whether the installation was successful with\n\n\n$ java -cp <WEKA-JAR-PATH> weka.core.WekaPackageManager \\\n       -list-packages installed\n\n\n\n\nwhich results in\n\n\nInstalled   Repository  Loaded  Package\n=========   ==========  ======  =======\n1.5.0       -----       Yes     <PACKAGE>: Weka wrappers for Deeplearning4j\n\n\n\n\nAdd GPU Support\n\n\nTo add GPU support, \ndownload\n and run the latest \ninstall-cuda-libs.sh\n for Linux/Macosx or \ninstall-cuda-libs.ps1\n for Windows. Make sure CUDA is installed on your system as explained \nhere\n.\n\n\nThe install script automatically downloads the libraries and copies them into your wekaDeeplearning4j package installation. If you want to download the library zip yourself, choose the appropriate combination of your platform and CUDA version from the \nlatest release\n and point the installation script to the file, e.g.:\n\n\n./install-cuda.sh ~/Downloads/wekaDeeplearning4j-cuda-9.1-1.5.0-linux-x86_64.zip\n\n\n\n\nUsing wekaDeeplearning4j in a Maven Project\n\n\nIt is also possible to include this package as maven project. As of now it is not provided in any maven repository, therefore you need to install this package to your local \n.m2\n repository:\n\n\n$ git clone https://github.com/Waikato/wekaDeeplearning4j.git\n$ cd wekaDeeplearning4j/package\n$ mvn clean install\n\n\n\n\n\nor, if you want the cuda version:\n\n\n$ mvn clean install -P <CUDA-VERSION> # Replace <CUDA-VERSION> with either \"8.0\", \"9.0\" or \"9.1\"\n\n\n\n\nNow you can add the maven dependency in your \npom.xml\n file \n\n\n<dependency>\n    <groupId>nz.ac.waikato.cms.weka</groupId>\n    <artifactId>wekaDeeplearning4j</artifactId>\n    <version>${wekaDeeplearning4j.version}</version>\n</dependency>",
            "title": "Installation"
        },
        {
            "location": "/install/#prerequisites",
            "text": "Weka 3.8.0 or above ( here )  WekaDeeplearning4j package 1.5.0 or above ( here )   You need to unzip the Weka zip file to a directory of your choice.",
            "title": "Prerequisites"
        },
        {
            "location": "/install/#cpu",
            "text": "For the package no further requisites are necessary.",
            "title": "CPU"
        },
        {
            "location": "/install/#gpu",
            "text": "The GPU additions needs the CUDA 8.0, 9.0 or 9.1 backend with the appropriate cuDNN library to be installed on your system. Nvidia provides some good installation instructions for all platforms:   Linux  Mac OS X  Windows",
            "title": "GPU"
        },
        {
            "location": "/install/#installing-the-weka-package",
            "text": "Weka packages can be easily installed either via the user interface as described  here , or simply via the commandline:  $ java -cp <WEKA-JAR-PATH> weka.core.WekaPackageManager \\\n       -install-package <PACKAGE-ZIP>  where  <WEKA-JAR-PATH>  must be replaced by the path pointing to the Weka jar file, and  <PACKAGE-ZIP>  is the wekaDeeplearning4j package zip file.  You can check whether the installation was successful with  $ java -cp <WEKA-JAR-PATH> weka.core.WekaPackageManager \\\n       -list-packages installed  which results in  Installed   Repository  Loaded  Package\n=========   ==========  ======  =======\n1.5.0       -----       Yes     <PACKAGE>: Weka wrappers for Deeplearning4j",
            "title": "Installing the Weka Package"
        },
        {
            "location": "/install/#add-gpu-support",
            "text": "To add GPU support,  download  and run the latest  install-cuda-libs.sh  for Linux/Macosx or  install-cuda-libs.ps1  for Windows. Make sure CUDA is installed on your system as explained  here .  The install script automatically downloads the libraries and copies them into your wekaDeeplearning4j package installation. If you want to download the library zip yourself, choose the appropriate combination of your platform and CUDA version from the  latest release  and point the installation script to the file, e.g.:  ./install-cuda.sh ~/Downloads/wekaDeeplearning4j-cuda-9.1-1.5.0-linux-x86_64.zip",
            "title": "Add GPU Support"
        },
        {
            "location": "/install/#using-wekadeeplearning4j-in-a-maven-project",
            "text": "It is also possible to include this package as maven project. As of now it is not provided in any maven repository, therefore you need to install this package to your local  .m2  repository:  $ git clone https://github.com/Waikato/wekaDeeplearning4j.git\n$ cd wekaDeeplearning4j/package\n$ mvn clean install  or, if you want the cuda version:  $ mvn clean install -P <CUDA-VERSION> # Replace <CUDA-VERSION> with either \"8.0\", \"9.0\" or \"9.1\"  Now you can add the maven dependency in your  pom.xml  file   <dependency>\n    <groupId>nz.ac.waikato.cms.weka</groupId>\n    <artifactId>wekaDeeplearning4j</artifactId>\n    <version>${wekaDeeplearning4j.version}</version>\n</dependency>",
            "title": "Using wekaDeeplearning4j in a Maven Project"
        },
        {
            "location": "/user-guide/getting-started/",
            "text": "Usage\n\n\nIf you are new to Weka, you should probably first start reading the \nWeka primer\n as a basic introduction.\n\n\nAs most of Weka, the WekaDeeplearning4j's functionality is accessible in three ways:\n\n\n\n\nVia the commandline interface\n\n\nProgramming with Weka in Java\n\n\nUsing the Weka workbench GUI\n\n\n\n\nAll three ways are explained in the following. The main classifier exposed by this package is named \nDl4jMlpClassifier\n.\nSimple examples are given in the examples section for the \nIris dataset\n and the \nMNIST dataset\n.\n\n\nMake sure your \nWEKA_HOME\n environment variable is set.\n\n\nCommandline Interface\n\n\nA first look for the available commandline options of the \nDl4jMlpClassifier\n is shown with\n\n\n$ java -cp $WEKA_HOME/weka.jar weka.Run .Dl4jMlpClassifier -h\n\n\n\n\nBelow the general options, the specific ones are listed:\n\n\nOptions specific to weka.classifiers.functions.Dl4jMlpClassifier:\n\n-S <num>\n    Random number seed.\n    (default 1)\n-logFile <string>\n    The name of the log file to write loss information to (default = no log file).\n-layer <string>\n    The specification of a layer. This option can be used multiple times.\n-numEpochs <int>\n    The number of epochs to perform.\n-iterator <string>\n    The dataset iterator to use.\n-config <string>\n    The neural network configuration to use.\n-normalization <int>\n    The type of normalization to perform.\n-queueSize <int>\n    The queue size for asynchronous data transfer (default: 0, synchronous transfer).\n-output-debug-info\n    If set, classifier is run in debug mode and\n    may output additional info to the console\n-do-not-check-capabilities\n    If set, classifier capabilities are not checked before classifier is built\n    (use with caution).\n-num-decimal-places\n    The number of decimal places for the output of numbers in the model (default 2).\n-batch-size\n    The desired batch size for batch prediction  (default 100).\n\n\n\n\nThe most interesting option may be the \n-layer\n specification. This option can be used multiple times and defines the architecture of the network layer-wise. \n\n\n$ java -cp $WEKA_HOME/weka.jar weka.Run \\\n       .Dl4jMlpClassifier \\\n       -layer \"weka.dl4j.layers.DenseLayer \\\n              -activation weka.dl4j.activations.ActivationReLU \\\n              -nOut 10\" \\\n       -layer \"weka.dl4j.layers.OutputLayer \\\n              -activation weka.dl4j.activations.ActivationSoftmax \\\n              -lossFn weka.dl4j.lossfunctions.LossMCXENT\" \n\n\n\n\nThe above setup builds a network with one hidden layer, having 10 output units using the ReLU activation function, followed by an output layer with the softmax activation function, using a multi-class cross-entropy loss function (MCXENT) as optimization objective.\n\n\nAnother important option is the neural network configuration \n-conf\n in which you can setup hyperparameters for the network. Available options can be found in the \nJava documentation\n (the field \ncommandLineParamSynopsis\n indicates the commandline parameter name for each available method).\n\n\nJava\n\n\nThe Java API is a straight forward wrapper for the official DeepLearning4j API. Using the \nDl4jMlPClassifier\n your code should usually start with\n\n\n// Create a new Multi-Layer-Perceptron classifier\nDl4jMlpClassifier clf = new Dl4jMlpClassifier();\n\n\n\n\nThe networks architecture can be set up by creating each layer step by step:\n\n\nDenseLayer denseLayer = new DenseLayer();\ndenseLayer.setNOut(10);\ndenseLayer.setActivationFn(new ActivationReLU());\n\n// Define the output layer\nOutputLayer outputLayer = new OutputLayer();\noutputLayer.setActivationFn(new ActivationSoftmax());\n\n\n\n\nFurther configuration can be done by setting a \nNeuralNetConfiguration\n\n\nNeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setUpdater(new Adam());\nclf.setNeuralNetConfiguration(nnc);\n\n\n\n\nFinally the layers are set with\n\n\n// Add the layers to the classifier\nclf.setLayers(denseLayer, outputLayer);\n\n\n\n\nWithout Maven\n\n\nIf you are not using the package in a maven project as described \nhere\n, you need to add the following directories to your java classpath\n\n\n\n\n$WEKA_HOME/packages/wekaDeeplearning4j/*\n\n\n$WEKA_HOME/packages/wekaDeeplearning4j/lib*\n\n\n\n\nAssuming you have the following \nMain.java\n file:\n\n\nimport weka.classifiers.Evaluation;\nimport weka.classifiers.functions.Dl4jMlpClassifier;\nimport weka.core.Instances;\n\nimport java.io.FileReader;\nimport java.nio.file.Paths;\nimport java.util.Random;\n\npublic class Main {\n    public static void main(String[] args) throws Exception {\n        Dl4jMlpClassifier clf = new Dl4jMlpClassifier();\n        String irisPath = Paths.get(System.getenv(\"WEKA_HOME\"), \"packages\", \"wekaDeeplearning4j\", \"datasets\", \"nominal\", \"iris.arff\").toString();\n        Instances inst = new Instances(new FileReader(irisPath));\n        inst.setClassIndex(inst.numAttributes() - 1);\n        Evaluation ev = new Evaluation(inst);\n        ev.crossValidateModel(clf, inst, 10, new Random(0));\n        System.out.println(ev.toSummaryString());\n    }\n}\n\n\n\n\nYou can now compile it including the libraries in the classpath:\n\n\njavac -cp \"$WEKA_HOME/weka.jar:$WEKA_HOME/packages/wekaDeeplearning4j/*:$WEKA_HOME/packages/wekaDeeplearning4j/lib/*\" Main.java\n\n\n\n\nand run it with:\n\n\njava -cp \"$WEKA_HOME/weka.jar:$WEKA_HOME/packages/wekaDeeplearning4j/*:$WEKA_HOME/packages/wekaDeeplearning4j/lib/*:.\" Main\n\n\n\n\n(Use \n;\n as classpath separator for Windows instead) \n\n\nGUI\n\n\nA tutorial on how to use the GUI is coming soon.\n\n\nModel Zoo\n\n\nWekaDeeplearning4j adapts the model zoo of Deeplearning4j. That means it is possible to load predefined architectures as neural network and train it on a new dataset. Currently implemented architectures are:\n\n\n\n\nAlexNet\n\n\nLeNet\n\n\nGoogLeNet\n\n\nSimpleCNN\n\n\nVGG16\n\n\nVGG19\n\n\n\n\nThis set of models will be extended over the time.\n\n\nTo set a predefined model, e.g. LeNet, from the model zoo, it is necessary to add the \n-zooModel \"weka.dl4j.zoo.LeNet\"\n option via commandline, or call the \nsetZooModel(new LeNet())\n on the \nDl4jMlpClassifier\n object.\n\n\nEarly Stopping\n\n\nEarly stopping allows to stop the training process as soon as the network does not improve its loss on a validation set for \nN\n epochs. \n\n\nThe setup below adds an early stopping condition that checks whether the loss score on 10% of the training data did not improve successively for 5 epochs.\n\n\nCommandline\n\n\n-early-stopping \"weka.dl4j.earlystopping.EarlyStopping -maxEpochsNoImprovement 5 -valPercentage 10\"\n\n\n\n\nJava\n\n\nEarlyStopping es = new EarlyStopping();\nes.setMaxEpochsNoImprovement(5);\nes.setValidationSetPercentage(10);\nclf.setEarlyStopping(es)\n\n\n\n\nor simpler\n\n\nclf.setEarlyStopping(new EarlyStopping(5, 10))\n\n\n\n\nGUI\n\n\nThe GUI provides a simple and intuitive interface to configure the early stopping parameters:",
            "title": "Getting Started"
        },
        {
            "location": "/user-guide/getting-started/#usage",
            "text": "If you are new to Weka, you should probably first start reading the  Weka primer  as a basic introduction.  As most of Weka, the WekaDeeplearning4j's functionality is accessible in three ways:   Via the commandline interface  Programming with Weka in Java  Using the Weka workbench GUI   All three ways are explained in the following. The main classifier exposed by this package is named  Dl4jMlpClassifier .\nSimple examples are given in the examples section for the  Iris dataset  and the  MNIST dataset .  Make sure your  WEKA_HOME  environment variable is set.",
            "title": "Usage"
        },
        {
            "location": "/user-guide/getting-started/#commandline-interface",
            "text": "A first look for the available commandline options of the  Dl4jMlpClassifier  is shown with  $ java -cp $WEKA_HOME/weka.jar weka.Run .Dl4jMlpClassifier -h  Below the general options, the specific ones are listed:  Options specific to weka.classifiers.functions.Dl4jMlpClassifier:\n\n-S <num>\n    Random number seed.\n    (default 1)\n-logFile <string>\n    The name of the log file to write loss information to (default = no log file).\n-layer <string>\n    The specification of a layer. This option can be used multiple times.\n-numEpochs <int>\n    The number of epochs to perform.\n-iterator <string>\n    The dataset iterator to use.\n-config <string>\n    The neural network configuration to use.\n-normalization <int>\n    The type of normalization to perform.\n-queueSize <int>\n    The queue size for asynchronous data transfer (default: 0, synchronous transfer).\n-output-debug-info\n    If set, classifier is run in debug mode and\n    may output additional info to the console\n-do-not-check-capabilities\n    If set, classifier capabilities are not checked before classifier is built\n    (use with caution).\n-num-decimal-places\n    The number of decimal places for the output of numbers in the model (default 2).\n-batch-size\n    The desired batch size for batch prediction  (default 100).  The most interesting option may be the  -layer  specification. This option can be used multiple times and defines the architecture of the network layer-wise.   $ java -cp $WEKA_HOME/weka.jar weka.Run \\\n       .Dl4jMlpClassifier \\\n       -layer \"weka.dl4j.layers.DenseLayer \\\n              -activation weka.dl4j.activations.ActivationReLU \\\n              -nOut 10\" \\\n       -layer \"weka.dl4j.layers.OutputLayer \\\n              -activation weka.dl4j.activations.ActivationSoftmax \\\n              -lossFn weka.dl4j.lossfunctions.LossMCXENT\"   The above setup builds a network with one hidden layer, having 10 output units using the ReLU activation function, followed by an output layer with the softmax activation function, using a multi-class cross-entropy loss function (MCXENT) as optimization objective.  Another important option is the neural network configuration  -conf  in which you can setup hyperparameters for the network. Available options can be found in the  Java documentation  (the field  commandLineParamSynopsis  indicates the commandline parameter name for each available method).",
            "title": "Commandline Interface"
        },
        {
            "location": "/user-guide/getting-started/#java",
            "text": "The Java API is a straight forward wrapper for the official DeepLearning4j API. Using the  Dl4jMlPClassifier  your code should usually start with  // Create a new Multi-Layer-Perceptron classifier\nDl4jMlpClassifier clf = new Dl4jMlpClassifier();  The networks architecture can be set up by creating each layer step by step:  DenseLayer denseLayer = new DenseLayer();\ndenseLayer.setNOut(10);\ndenseLayer.setActivationFn(new ActivationReLU());\n\n// Define the output layer\nOutputLayer outputLayer = new OutputLayer();\noutputLayer.setActivationFn(new ActivationSoftmax());  Further configuration can be done by setting a  NeuralNetConfiguration  NeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setUpdater(new Adam());\nclf.setNeuralNetConfiguration(nnc);  Finally the layers are set with  // Add the layers to the classifier\nclf.setLayers(denseLayer, outputLayer);",
            "title": "Java"
        },
        {
            "location": "/user-guide/getting-started/#without-maven",
            "text": "If you are not using the package in a maven project as described  here , you need to add the following directories to your java classpath   $WEKA_HOME/packages/wekaDeeplearning4j/*  $WEKA_HOME/packages/wekaDeeplearning4j/lib*   Assuming you have the following  Main.java  file:  import weka.classifiers.Evaluation;\nimport weka.classifiers.functions.Dl4jMlpClassifier;\nimport weka.core.Instances;\n\nimport java.io.FileReader;\nimport java.nio.file.Paths;\nimport java.util.Random;\n\npublic class Main {\n    public static void main(String[] args) throws Exception {\n        Dl4jMlpClassifier clf = new Dl4jMlpClassifier();\n        String irisPath = Paths.get(System.getenv(\"WEKA_HOME\"), \"packages\", \"wekaDeeplearning4j\", \"datasets\", \"nominal\", \"iris.arff\").toString();\n        Instances inst = new Instances(new FileReader(irisPath));\n        inst.setClassIndex(inst.numAttributes() - 1);\n        Evaluation ev = new Evaluation(inst);\n        ev.crossValidateModel(clf, inst, 10, new Random(0));\n        System.out.println(ev.toSummaryString());\n    }\n}  You can now compile it including the libraries in the classpath:  javac -cp \"$WEKA_HOME/weka.jar:$WEKA_HOME/packages/wekaDeeplearning4j/*:$WEKA_HOME/packages/wekaDeeplearning4j/lib/*\" Main.java  and run it with:  java -cp \"$WEKA_HOME/weka.jar:$WEKA_HOME/packages/wekaDeeplearning4j/*:$WEKA_HOME/packages/wekaDeeplearning4j/lib/*:.\" Main  (Use  ;  as classpath separator for Windows instead)",
            "title": "Without Maven"
        },
        {
            "location": "/user-guide/getting-started/#gui",
            "text": "A tutorial on how to use the GUI is coming soon.",
            "title": "GUI"
        },
        {
            "location": "/user-guide/getting-started/#model-zoo",
            "text": "WekaDeeplearning4j adapts the model zoo of Deeplearning4j. That means it is possible to load predefined architectures as neural network and train it on a new dataset. Currently implemented architectures are:   AlexNet  LeNet  GoogLeNet  SimpleCNN  VGG16  VGG19   This set of models will be extended over the time.  To set a predefined model, e.g. LeNet, from the model zoo, it is necessary to add the  -zooModel \"weka.dl4j.zoo.LeNet\"  option via commandline, or call the  setZooModel(new LeNet())  on the  Dl4jMlpClassifier  object.",
            "title": "Model Zoo"
        },
        {
            "location": "/user-guide/getting-started/#early-stopping",
            "text": "Early stopping allows to stop the training process as soon as the network does not improve its loss on a validation set for  N  epochs.   The setup below adds an early stopping condition that checks whether the loss score on 10% of the training data did not improve successively for 5 epochs.  Commandline  -early-stopping \"weka.dl4j.earlystopping.EarlyStopping -maxEpochsNoImprovement 5 -valPercentage 10\"  Java  EarlyStopping es = new EarlyStopping();\nes.setMaxEpochsNoImprovement(5);\nes.setValidationSetPercentage(10);\nclf.setEarlyStopping(es)  or simpler  clf.setEarlyStopping(new EarlyStopping(5, 10))  GUI  The GUI provides a simple and intuitive interface to configure the early stopping parameters:",
            "title": "Early Stopping"
        },
        {
            "location": "/user-guide/data/",
            "text": "Loading Data\n\n\nThe package provides so called \nInstanceIterators\n to load the given dataset in a correct shape. Each iterator allows to set a batch size which refer to the mini batches used for training a network. The following explains for which dataset and network type which iterator is necessary.\n\n\nDefaultInstanceIterator\n\n\nThe \nDefaultInstanceIterator\n assumes your dataset is of the following shape\n\n\n@RELATION iris\n\n@ATTRIBUTE sepallength  REAL\n@ATTRIBUTE sepalwidth   REAL\n@ATTRIBUTE petallength  REAL\n@ATTRIBUTE petalwidth   REAL\n@ATTRIBUTE class        {Iris-setosa,Iris-versicolor,Iris-virginica}\n\n@DATA\n5.1,3.5,1.4,0.2,Iris-setosa\n4.9,3.0,1.4,0.2,Iris-setosa\n4.7,3.2,1.3,0.2,Iris-setosa\n...\n\n\n\n\nthat is, each row is represented as a vector without further interpretation\nand you want to build a simple dense network of the form\n\n\nDenseLayer -> DenseLayer -> ... -> OutputLayer\n\n\n\n\nConvolutionInstanceIterator\n\n\nTo use convolutional neural networks in the case of a more sophisticated dataset, where the ARFF file represents column-wise flattened image pixels as e.g.:\n\n\n@RELATION hotdog-3x3\n\n@ATTRIBUTE pixel00  REAL\n@ATTRIBUTE pixel01  REAL\n@ATTRIBUTE pixel02  REAL\n@ATTRIBUTE pixel10  REAL\n@ATTRIBUTE pixel11  REAL\n@ATTRIBUTE pixel12  REAL\n@ATTRIBUTE pixel20  REAL\n@ATTRIBUTE pixel21  REAL\n@ATTRIBUTE pixel22  REAL\n\n@ATTRIBUTE class    {hotdog, not-hotdog}\n\n@DATA\n127,32,15,234,214,144,94,43,23,hotdog\n52,14,244,232,241,11,142,211,211,not-hotdog\n...\n\n\n\n\nit is necessary to set the iterator to \nConvolutionInstanceIterator\n. \n\n\nAvailable parameters:\n\n\n\n\nheight\n: Height of the images\n\n\nwidth\n: Width of the images\n\n\nnumChannels\n: Depth of the image (e.g.: RGB images have a depth of 3, whereas Greyscale images have a depth of 1)\n\n\n\n\nImageInstanceIterator\n\n\nIf the dataset consists of a set of image files it is necessary to prepare a meta data ARFF file in the following format:\n\n\n@RELATION mnist.meta.minimal\n\n@ATTRIBUTE filename string\n@ATTRIBUTE class {0,1,2,3,4,5,6,7,8,9}\n\n@DATA\nimg_12829_0.jpg,0\nimg_32870_0.jpg,0\nimg_28642_0.jpg,0\n...\n\n\n\n\nThis file informs the internals about the association between the image files and their labels. Additionally it is mandatory to set the iterator to \nImageInstanceIterator\n. \n\n\nAvailable parameters:\n\n\n\n\nheight\n: Height of the images\n\n\nwidth\n: Width of the images\n\n\nnumChannels\n: Depth of the image (e.g.: RGB images have a depth of 3, whereas Greyscale images have a depth of 1)\n\n\nimagesLocation\n: The absolute path to the location of the images listed in the meta-data ARFF file\n\n\n\n\nCnn/RnnTextEmbeddingInstanceIterator\n\n\nIf you are going to process text data, it is usually necessary to project the documents into an embedding space. This means, each token (e.g. a word) is mapped with the help of an embedding into a certain feature space. That is, each document will then contain a series of vectors, where each vector represents a token in the embedding space. The \nCnn/RnnTextEmbeddingInstanceIterator\n accepts datasets containing a document and a class as shown below:\n\n\n@RELATION 'imdb-reviews'\n\n@ATTRIBUTE review string\n@ATTRIBUTE class-att {pos,neg}\n\n@data\n\"Prince stars as the Kid in this semi-autobiographical film ...\",pos\n\"I just saw Behind Bedroom Doors and this was the first ...\",neg\n...\n\n\n\n\nAvailable parameters:\n\n\n\n\nwordVectorLocation\n: File which provides the iterator with a serialized word embedding\n\n\nstopWords\n: Stopword strategy to filter unnecessary words\n\n\ntokenizerFactory\n: Defines how tokens are created\n\n\ntokenPreProcess\n: Defines how tokens are preprocessed\n\n\ntruncateLength\n: Maximum number of words per document\n\n\n\n\nCnn/RnnTextFilesEmbeddingInstanceIterator\n\n\nThis iterator extends the \nCnn/RnnTextEmbeddingInstanceIterator\n and allows the use of distributed documents that are not collected in a single ARFF file. Similar to the \nImageInstanceIterator\n, this iterator is applicable to an ARFF file containing the meta data, such as:\n\n\n@RELATION 'imdb-reviews'\n\n@ATTRIBUTE document-path string\n@ATTRIBUTE class-att {pos,neg}\n\n@data\nreview_0.txt,pos\nreview_1.txt,neg\n...\n\n\n\n\nAvailable parameters:\n\n\n\n\nwordVectorLocation\n: File which provides the iterator with a serialized word embedding\n\n\nstopWords\n: Stopword strategy to filter unnecessary words\n\n\ntokenizerFactory\n: Defines how tokens are created\n\n\ntokenPreProcess\n: Defines how tokens are preprocessed\n\n\ntruncateLength\n: Maximum number of words per document\n\n\ntextsLocation\n: The absolute path to the location of the text files listed in the meta data ARFF file\n\n\n\n\nRelationalInstanceIterator\n\n\nThe \nRelationalInstanceIterator\n is useful for ARFF datasets that make use of the \nrelational\n attribute type such as in the following:\n\n\n@relation musk1\n\n@attribute bag relational\n   @attribute f1 numeric\n   @attribute f2 numeric\n   @attribute f3 numeric\n   @attribute f4 numeric\n   @attribute f5 numeric\n   ...\n   @attribute f166 numeric\n@end bag\n@attribute class {0,1}\n\n@data\n\"42,-198,-109,-75,-117,11,23,-88,-28,-27,...,48,-37,6,30\\n42,-191,-142,-65,-117,55,49,-170,-45,5,...,48,-37,5,30\\n...\",1\n ...\n\n\n\n\nEach row in the dataset can be a multivariate sequence. Therefore, this format is useful for representing timeseries data. The \nRnnSequenceClassifier\n can thus use this iterator to perform classification and regression on multivariate sequences.\n\n\nAvailable parameters:\n\n\n\n\ntruncateLength\n: Maximum sequence lengthARFF file\n\n\nrelationalAttributeIndex\n: Index of the relational attribute in the given dataset\n\n\n\n\nCaching\n\n\nThe iterators allow to choose between three modes of caching:\n\n\n\n\nNONE\n: disable caches\n\n\nMEMORY\n: cache the generated mini batches in memory\n\n\nFILESYSTEM\n: cache the generated mini batches in the filesystem (in your system's temporary directory)\n\n\n\n\nThe cache will be built up in the first epoch. For further epochs, the batches do not need to be recomputed but are read from the cache. This might help if the batch generation is computational intensive.",
            "title": "Loading Data"
        },
        {
            "location": "/user-guide/data/#loading-data",
            "text": "The package provides so called  InstanceIterators  to load the given dataset in a correct shape. Each iterator allows to set a batch size which refer to the mini batches used for training a network. The following explains for which dataset and network type which iterator is necessary.",
            "title": "Loading Data"
        },
        {
            "location": "/user-guide/data/#defaultinstanceiterator",
            "text": "The  DefaultInstanceIterator  assumes your dataset is of the following shape  @RELATION iris\n\n@ATTRIBUTE sepallength  REAL\n@ATTRIBUTE sepalwidth   REAL\n@ATTRIBUTE petallength  REAL\n@ATTRIBUTE petalwidth   REAL\n@ATTRIBUTE class        {Iris-setosa,Iris-versicolor,Iris-virginica}\n\n@DATA\n5.1,3.5,1.4,0.2,Iris-setosa\n4.9,3.0,1.4,0.2,Iris-setosa\n4.7,3.2,1.3,0.2,Iris-setosa\n...  that is, each row is represented as a vector without further interpretation\nand you want to build a simple dense network of the form  DenseLayer -> DenseLayer -> ... -> OutputLayer",
            "title": "DefaultInstanceIterator"
        },
        {
            "location": "/user-guide/data/#convolutioninstanceiterator",
            "text": "To use convolutional neural networks in the case of a more sophisticated dataset, where the ARFF file represents column-wise flattened image pixels as e.g.:  @RELATION hotdog-3x3\n\n@ATTRIBUTE pixel00  REAL\n@ATTRIBUTE pixel01  REAL\n@ATTRIBUTE pixel02  REAL\n@ATTRIBUTE pixel10  REAL\n@ATTRIBUTE pixel11  REAL\n@ATTRIBUTE pixel12  REAL\n@ATTRIBUTE pixel20  REAL\n@ATTRIBUTE pixel21  REAL\n@ATTRIBUTE pixel22  REAL\n\n@ATTRIBUTE class    {hotdog, not-hotdog}\n\n@DATA\n127,32,15,234,214,144,94,43,23,hotdog\n52,14,244,232,241,11,142,211,211,not-hotdog\n...  it is necessary to set the iterator to  ConvolutionInstanceIterator .",
            "title": "ConvolutionInstanceIterator"
        },
        {
            "location": "/user-guide/data/#available-parameters",
            "text": "height : Height of the images  width : Width of the images  numChannels : Depth of the image (e.g.: RGB images have a depth of 3, whereas Greyscale images have a depth of 1)",
            "title": "Available parameters:"
        },
        {
            "location": "/user-guide/data/#imageinstanceiterator",
            "text": "If the dataset consists of a set of image files it is necessary to prepare a meta data ARFF file in the following format:  @RELATION mnist.meta.minimal\n\n@ATTRIBUTE filename string\n@ATTRIBUTE class {0,1,2,3,4,5,6,7,8,9}\n\n@DATA\nimg_12829_0.jpg,0\nimg_32870_0.jpg,0\nimg_28642_0.jpg,0\n...  This file informs the internals about the association between the image files and their labels. Additionally it is mandatory to set the iterator to  ImageInstanceIterator .",
            "title": "ImageInstanceIterator"
        },
        {
            "location": "/user-guide/data/#available-parameters_1",
            "text": "height : Height of the images  width : Width of the images  numChannels : Depth of the image (e.g.: RGB images have a depth of 3, whereas Greyscale images have a depth of 1)  imagesLocation : The absolute path to the location of the images listed in the meta-data ARFF file",
            "title": "Available parameters:"
        },
        {
            "location": "/user-guide/data/#cnnrnntextembeddinginstanceiterator",
            "text": "If you are going to process text data, it is usually necessary to project the documents into an embedding space. This means, each token (e.g. a word) is mapped with the help of an embedding into a certain feature space. That is, each document will then contain a series of vectors, where each vector represents a token in the embedding space. The  Cnn/RnnTextEmbeddingInstanceIterator  accepts datasets containing a document and a class as shown below:  @RELATION 'imdb-reviews'\n\n@ATTRIBUTE review string\n@ATTRIBUTE class-att {pos,neg}\n\n@data\n\"Prince stars as the Kid in this semi-autobiographical film ...\",pos\n\"I just saw Behind Bedroom Doors and this was the first ...\",neg\n...",
            "title": "Cnn/RnnTextEmbeddingInstanceIterator"
        },
        {
            "location": "/user-guide/data/#available-parameters_2",
            "text": "wordVectorLocation : File which provides the iterator with a serialized word embedding  stopWords : Stopword strategy to filter unnecessary words  tokenizerFactory : Defines how tokens are created  tokenPreProcess : Defines how tokens are preprocessed  truncateLength : Maximum number of words per document",
            "title": "Available parameters:"
        },
        {
            "location": "/user-guide/data/#cnnrnntextfilesembeddinginstanceiterator",
            "text": "This iterator extends the  Cnn/RnnTextEmbeddingInstanceIterator  and allows the use of distributed documents that are not collected in a single ARFF file. Similar to the  ImageInstanceIterator , this iterator is applicable to an ARFF file containing the meta data, such as:  @RELATION 'imdb-reviews'\n\n@ATTRIBUTE document-path string\n@ATTRIBUTE class-att {pos,neg}\n\n@data\nreview_0.txt,pos\nreview_1.txt,neg\n...",
            "title": "Cnn/RnnTextFilesEmbeddingInstanceIterator"
        },
        {
            "location": "/user-guide/data/#available-parameters_3",
            "text": "wordVectorLocation : File which provides the iterator with a serialized word embedding  stopWords : Stopword strategy to filter unnecessary words  tokenizerFactory : Defines how tokens are created  tokenPreProcess : Defines how tokens are preprocessed  truncateLength : Maximum number of words per document  textsLocation : The absolute path to the location of the text files listed in the meta data ARFF file",
            "title": "Available parameters:"
        },
        {
            "location": "/user-guide/data/#relationalinstanceiterator",
            "text": "The  RelationalInstanceIterator  is useful for ARFF datasets that make use of the  relational  attribute type such as in the following:  @relation musk1\n\n@attribute bag relational\n   @attribute f1 numeric\n   @attribute f2 numeric\n   @attribute f3 numeric\n   @attribute f4 numeric\n   @attribute f5 numeric\n   ...\n   @attribute f166 numeric\n@end bag\n@attribute class {0,1}\n\n@data\n\"42,-198,-109,-75,-117,11,23,-88,-28,-27,...,48,-37,6,30\\n42,-191,-142,-65,-117,55,49,-170,-45,5,...,48,-37,5,30\\n...\",1\n ...  Each row in the dataset can be a multivariate sequence. Therefore, this format is useful for representing timeseries data. The  RnnSequenceClassifier  can thus use this iterator to perform classification and regression on multivariate sequences.",
            "title": "RelationalInstanceIterator"
        },
        {
            "location": "/user-guide/data/#available-parameters_4",
            "text": "truncateLength : Maximum sequence lengthARFF file  relationalAttributeIndex : Index of the relational attribute in the given dataset",
            "title": "Available parameters:"
        },
        {
            "location": "/user-guide/data/#caching",
            "text": "The iterators allow to choose between three modes of caching:   NONE : disable caches  MEMORY : cache the generated mini batches in memory  FILESYSTEM : cache the generated mini batches in the filesystem (in your system's temporary directory)   The cache will be built up in the first epoch. For further epochs, the batches do not need to be recomputed but are read from the cache. This might help if the batch generation is computational intensive.",
            "title": "Caching"
        },
        {
            "location": "/user-guide/nlp/",
            "text": "Text Processing in WekaDeeplearning4J\n\n\nThere are currently two main deep learning architectures supported to process text data, as explained in the below.\nText can be interpreted as a sequence of so called \ntokens\n, where a token can be e.g. a character, word, sentence or even a whole document. These tokens can further be mapped with the help of an \nembedding\n into a vector space defined by the embedding. Therefore, a text document can be represented as a sequence of vectors. This can be achieved by using the \nCnn/RnnTextEmbeddingInstanceIterator\n and providing an embedding that was previously downloaded (e.g. Google's pretrained News model from \nhere\n). \n\n\nUsing Convolutional Neural Networks\n\n\nTo use convolution on text data, it is necessary to correctly preprocess the input into a certain shape and make sure to set the convolution layers accordingly. A good blog post on this is \nUnderstanding Convolutional Neural Networks for NLP\n.\n\n\nA few important things to keep in mind when building a CNN on text data:\n\n\n\n\nStart with \nConvolutionLayer\n\n\nAdding multiple \nConvolutionLayer\n sequentially will simulate an input for each layer and merge the output of all layers to a new output with the number of layer as depth\n\n\nConvolutionMode\n of each \nConvolutionLayer\n must be set to \nSAME\n\n\nThe list of \nConvolutionLayer\n must be followed by a \nGlobalPoolingLayer\n\n\n\n\nSee also: \nJava Examples\n\n\nUse the \nCnnTextEmbeddingInstanceIterator\n or \nCnnTextFilesEmbeddingInstanceIterator\n accordingly.\n\n\nUsing Recurrent Neural Networks\n\n\nThe \nRnnSequenceClassifier\n allows for the construction of neural networks containing recurrent units. The following layer types are supported for these architectures:\n\n\n\n\nLSTM\n\n\nGravesLSTM\n\n\nRnnOutputLayer\n\n\n\n\nUse the \nRnnTextEmbeddingInstanceIterator\n or \nRnnTextFilesEmbeddingInstanceIterator\n accordingly.\n\n\nEmbeddings\n\n\nCurrently supported embedding formats are:\n\n\n\n\nARFF\n\n\nCSV\n\n\nCSV gzipped\n\n\nGoogle binary format\n\n\nDL4J compressed format\n\n\n\n\nWeka Filters\n\n\n\n\nDl4jStringToWord2Vec\n: calculates word embeddings on a string attribute using the \nWord2Vec\n method\n\n\nDl4jStringToGlove\n: calculates word embeddings on a string attribute using the \nGlove\n method.",
            "title": "Natural Language Processing"
        },
        {
            "location": "/user-guide/nlp/#text-processing-in-wekadeeplearning4j",
            "text": "There are currently two main deep learning architectures supported to process text data, as explained in the below.\nText can be interpreted as a sequence of so called  tokens , where a token can be e.g. a character, word, sentence or even a whole document. These tokens can further be mapped with the help of an  embedding  into a vector space defined by the embedding. Therefore, a text document can be represented as a sequence of vectors. This can be achieved by using the  Cnn/RnnTextEmbeddingInstanceIterator  and providing an embedding that was previously downloaded (e.g. Google's pretrained News model from  here ).",
            "title": "Text Processing in WekaDeeplearning4J"
        },
        {
            "location": "/user-guide/nlp/#using-convolutional-neural-networks",
            "text": "To use convolution on text data, it is necessary to correctly preprocess the input into a certain shape and make sure to set the convolution layers accordingly. A good blog post on this is  Understanding Convolutional Neural Networks for NLP .  A few important things to keep in mind when building a CNN on text data:   Start with  ConvolutionLayer  Adding multiple  ConvolutionLayer  sequentially will simulate an input for each layer and merge the output of all layers to a new output with the number of layer as depth  ConvolutionMode  of each  ConvolutionLayer  must be set to  SAME  The list of  ConvolutionLayer  must be followed by a  GlobalPoolingLayer   See also:  Java Examples  Use the  CnnTextEmbeddingInstanceIterator  or  CnnTextFilesEmbeddingInstanceIterator  accordingly.",
            "title": "Using Convolutional Neural Networks"
        },
        {
            "location": "/user-guide/nlp/#using-recurrent-neural-networks",
            "text": "The  RnnSequenceClassifier  allows for the construction of neural networks containing recurrent units. The following layer types are supported for these architectures:   LSTM  GravesLSTM  RnnOutputLayer   Use the  RnnTextEmbeddingInstanceIterator  or  RnnTextFilesEmbeddingInstanceIterator  accordingly.",
            "title": "Using Recurrent Neural Networks"
        },
        {
            "location": "/user-guide/nlp/#embeddings",
            "text": "Currently supported embedding formats are:   ARFF  CSV  CSV gzipped  Google binary format  DL4J compressed format",
            "title": "Embeddings"
        },
        {
            "location": "/user-guide/nlp/#weka-filters",
            "text": "Dl4jStringToWord2Vec : calculates word embeddings on a string attribute using the  Word2Vec  method  Dl4jStringToGlove : calculates word embeddings on a string attribute using the  Glove  method.",
            "title": "Weka Filters"
        },
        {
            "location": "/examples/classifying-iris/",
            "text": "The Iris Dataset\n\n\nA very common dataset to test algorithms with is the \nIris Dataset\n . The following explains how to build a neural network from the command line, programmatically in java and in the Weka workbench GUI.\n\n\nThe iris dataset can be found in the \ndatasets/nominal\n directory of the WekaDeeplearning4j package.\n\n\n \n  \nIris Visualization \n\n  \n\n\n\n\nCommandline\n\n\nStarting simple, the most straight forward way to create a neural network with this package is by using the commandline. A Single-Layer-Perceptron (the most basic neural network possible) is shown in the following\n\n\n$ java -cp $WEKA_HOME/weka.jar weka.Run \\\n        .Dl4jMlpClassifier \\\n        -S 1 \\\n        -layer \"weka.dl4j.layers.OutputLayer \\\n                -activation weka.dl4j.activations.ActivationSoftmax \\\n                -lossFn weka.dl4j.lossfunctions.LossMCXENT\" \\\n        -config \"weka.dl4j.NeuralNetConfiguration \\\n                -updater weka.dl4j.updater.Adam\" \\\n        -numEpochs 10 \\\n        -t datasets/nominal/iris.arff \\\n        -split-percentage 66\n\n\n\n\nJava\n\n\nThe same architecture can be built programmatically with the following Java code\n\n\n// Create a new Multi-Layer-Perceptron classifier\nDl4jMlpClassifier clf = new Dl4jMlpClassifier();\n// Set a seed for reproducable results\nclf.setSeed(1);\n\n// Load the iris dataset and set its class index\nInstances data = new Instances(new FileReader(\"datasets/nominal/iris.arff\"));\ndata.setClassIndex(data.numAttributes() - 1);\n\n// Define the output layer\nOutputLayer outputLayer = new OutputLayer();\noutputLayer.setActivationFn(new ActivationSoftmax());\noutputLayer.setLossFn(new LossMCXENT());\n\nNeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setUpdater(new Adam());\n\n// Add the layers to the classifier\nclf.setLayers(new Layer[]{outputLayer});\nclf.setNeuralNetConfiguration(nnc);\n\n// Evaluate the network\nEvaluation eval = new Evaluation(data);\nint numFolds = 10;\neval.crossValidateModel(clf, data, numFolds, new Random(1));\n\nSystem.out.println(eval.toSummaryString());",
            "title": "Classifying the Iris Dataset"
        },
        {
            "location": "/examples/classifying-iris/#the-iris-dataset",
            "text": "A very common dataset to test algorithms with is the  Iris Dataset  . The following explains how to build a neural network from the command line, programmatically in java and in the Weka workbench GUI.  The iris dataset can be found in the  datasets/nominal  directory of the WekaDeeplearning4j package.   \n   Iris Visualization",
            "title": "The Iris Dataset"
        },
        {
            "location": "/examples/classifying-iris/#commandline",
            "text": "Starting simple, the most straight forward way to create a neural network with this package is by using the commandline. A Single-Layer-Perceptron (the most basic neural network possible) is shown in the following  $ java -cp $WEKA_HOME/weka.jar weka.Run \\\n        .Dl4jMlpClassifier \\\n        -S 1 \\\n        -layer \"weka.dl4j.layers.OutputLayer \\\n                -activation weka.dl4j.activations.ActivationSoftmax \\\n                -lossFn weka.dl4j.lossfunctions.LossMCXENT\" \\\n        -config \"weka.dl4j.NeuralNetConfiguration \\\n                -updater weka.dl4j.updater.Adam\" \\\n        -numEpochs 10 \\\n        -t datasets/nominal/iris.arff \\\n        -split-percentage 66",
            "title": "Commandline"
        },
        {
            "location": "/examples/classifying-iris/#java",
            "text": "The same architecture can be built programmatically with the following Java code  // Create a new Multi-Layer-Perceptron classifier\nDl4jMlpClassifier clf = new Dl4jMlpClassifier();\n// Set a seed for reproducable results\nclf.setSeed(1);\n\n// Load the iris dataset and set its class index\nInstances data = new Instances(new FileReader(\"datasets/nominal/iris.arff\"));\ndata.setClassIndex(data.numAttributes() - 1);\n\n// Define the output layer\nOutputLayer outputLayer = new OutputLayer();\noutputLayer.setActivationFn(new ActivationSoftmax());\noutputLayer.setLossFn(new LossMCXENT());\n\nNeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setUpdater(new Adam());\n\n// Add the layers to the classifier\nclf.setLayers(new Layer[]{outputLayer});\nclf.setNeuralNetConfiguration(nnc);\n\n// Evaluate the network\nEvaluation eval = new Evaluation(data);\nint numFolds = 10;\neval.crossValidateModel(clf, data, numFolds, new Random(1));\n\nSystem.out.println(eval.toSummaryString());",
            "title": "Java"
        },
        {
            "location": "/examples/classifying-mnist/",
            "text": "The MNIST Dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe MNIST dataset provides images of handwritten digits of 10 classes (0-9) and suits the task of simple image classification. \n\n\nThe minimal MNIST arff file can be found in the \ndatasets/nominal\n directory of the WekaDeeplearning4j package. This arff file lists all images in \ndatasets/nominal/mnist-minimal\n and annotates their path with their class label.\n\n\nImportant note:\n The arff dataset contains two features, the first one being the \nfilename\n and the second one being the \nclass\n. Therefore it is necessary to define an \nImageDataSetIterator\n which uses these filenames in the directory given by the option \n-imagesLocation\n.\n\n\nCommandline\n\n\nThe following run creates a Conv(3x3x8) > Pool(2x2,MAX) > Conv(3x3x8) > Pool(2x2,MAX) > Out architecture\n\n\n$ java -Xmx5g -cp $WEKA_HOME/weka.jar weka.Run \\\n     .Dl4jMlpClassifier \\\n     -S 1 \\\n     -iterator \"weka.dl4j.iterators.instance.ImageInstanceIterator -imagesLocation datasets/nominal/mnist-minimal -numChannels 1 -height 28 -width 28 -bs 16\" \\\n     -normalization \"Standardize training data\" \\\n     -layer \"weka.dl4j.layers.ConvolutionLayer -nFilters 8 -activation weka.dl4j.activations.ActivationReLU -kernelSizeX 3 -kernelSizeY 3 -paddingX 0 -paddingY 0 -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.SubsamplingLayer -kernelSizeX 2 -kernelSizeY 2 -paddingX 0 -paddingY 0 -poolingType MAX -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.ConvolutionLayer -nFilters 8 -activation weka.dl4j.activations.ActivationReLU -kernelSizeX 3 -kernelSizeY 3 -paddingX 0 -paddingY 0 -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.SubsamplingLayer -kernelSizeX 2 -kernelSizeY 2 -paddingX 0 -paddingY 0 -poolingType MAX -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.OutputLayer -activation weka.dl4j.activations.ActivationSoftmax -lossFn weka.dl4j.lossfunctions.LossMCXENT\" \\\n     -config \"weka.dl4j.NeuralNetConfiguration -updater weka.dl4j.updater.Adam\" \\\n     -numEpochs 10 \\\n     -t datasets/nominal/mnist.meta.minimal.arff \\\n     -split-percentage 80\n\n\n\n\nJava\n\n\nThe same architecture can be built programmatically with the following Java code\n\n\n// Set up the MLP classifier\nDl4jMlpClassifier clf = new Dl4jMlpClassifier();\nclf.setSeed(1);\nclf.setNumEpochs(10);\n\n\n// Load the arff file\nInstances data = new Instances(new FileReader(\"datasets/nominal/mnist.meta.minimal.arff\"));\ndata.setClassIndex(data.numAttributes() - 1);\n\n\n// Load the image iterator\nImageDataSetIterator imgIter = new ImageDataSetIterator();\nimgIter.setImagesLocation(new File(\"datasets/nominal/mnist-minimal\"));\nimgIter.setHeight(28);\nimgIter.setWidth(28);\nimgIter.setNumChannels(1);\nimgIter.setTrainBatchSize(16);\nclf.setDataSetIterator(imgIter);\n\n\n// Setup the network layers\n// First convolution layer, 8 3x3 filter \nConvolutionLayer convLayer1 = new ConvolutionLayer();\nconvLayer1.setKernelSizeX(3);\nconvLayer1.setKernelSizeY(3);\nconvLayer1.setStrideX(1);\nconvLayer1.setStrideY(1);\nconvLayer1.setActivationFn(new ActivationReLU());\nconvLayer1.setNOut(8);\n\n// First maxpooling layer, 2x2 filter\nSubsamplingLayer poolLayer1 = new SubsamplingLayer();\npoolLayer1.setPoolingType(PoolingType.MAX);\npoolLayer1.setKernelSizeX(2);\npoolLayer1.setKernelSizeY(2);\npoolLayer1.setStrideX(1);\npoolLayer1.setStrideY(1);\n\n// Second convolution layer, 8 3x3 filter\nConvolutionLayer convLayer2 = new ConvolutionLayer();\nconvLayer2.setKernelSizeX(3);\nconvLayer2.setKernelSizeY(3);\nconvLayer2.setStrideX(1);\nconvLayer2.setStrideY(1);\nconvLayer2.setActivationFn(new ActivationReLU());\nconvLayer2.setNOut(8);\n\n// Second maxpooling layer, 2x2 filter\nSubsamplingLayer poolLayer2 = new SubsamplingLayer();\npoolLayer2.setPoolingType(PoolingType.MAX);\npoolLayer2.setKernelSizeX(2);\npoolLayer2.setKernelSizeY(2);\npoolLayer2.setStrideX(1);\npoolLayer2.setStrideY(1);\n\n// Output layer with softmax activation\nOutputLayer outputLayer = new OutputLayer();\noutputLayer.setActivationFn(new ActivationSoftmax());\noutputLayer.setLossFn(new LossMCXENT());\n\n\n// Set up the network configuration\nNeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setUpdater(new Adam());\nclf.setNeuralNetConfiguration(nnc);\n\n\n// Set the layers\nclf.setLayers(new Layer[]{convLayer1, poolLayer1, convLayer2, poolLayer2, outputLayer});\n\n\n// Evaluate the network\nEvaluation eval = new Evaluation(data);\nint numFolds = 10;\neval.crossValidateModel(clf, data, numFolds, new Random(1));\n\nSystem.out.println(\"% Correct = \" + eval.pctCorrect());",
            "title": "Classifying the MNIST Dataset"
        },
        {
            "location": "/examples/classifying-mnist/#the-mnist-dataset",
            "text": "The MNIST dataset provides images of handwritten digits of 10 classes (0-9) and suits the task of simple image classification.   The minimal MNIST arff file can be found in the  datasets/nominal  directory of the WekaDeeplearning4j package. This arff file lists all images in  datasets/nominal/mnist-minimal  and annotates their path with their class label.  Important note:  The arff dataset contains two features, the first one being the  filename  and the second one being the  class . Therefore it is necessary to define an  ImageDataSetIterator  which uses these filenames in the directory given by the option  -imagesLocation .",
            "title": "The MNIST Dataset"
        },
        {
            "location": "/examples/classifying-mnist/#commandline",
            "text": "The following run creates a Conv(3x3x8) > Pool(2x2,MAX) > Conv(3x3x8) > Pool(2x2,MAX) > Out architecture  $ java -Xmx5g -cp $WEKA_HOME/weka.jar weka.Run \\\n     .Dl4jMlpClassifier \\\n     -S 1 \\\n     -iterator \"weka.dl4j.iterators.instance.ImageInstanceIterator -imagesLocation datasets/nominal/mnist-minimal -numChannels 1 -height 28 -width 28 -bs 16\" \\\n     -normalization \"Standardize training data\" \\\n     -layer \"weka.dl4j.layers.ConvolutionLayer -nFilters 8 -activation weka.dl4j.activations.ActivationReLU -kernelSizeX 3 -kernelSizeY 3 -paddingX 0 -paddingY 0 -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.SubsamplingLayer -kernelSizeX 2 -kernelSizeY 2 -paddingX 0 -paddingY 0 -poolingType MAX -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.ConvolutionLayer -nFilters 8 -activation weka.dl4j.activations.ActivationReLU -kernelSizeX 3 -kernelSizeY 3 -paddingX 0 -paddingY 0 -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.SubsamplingLayer -kernelSizeX 2 -kernelSizeY 2 -paddingX 0 -paddingY 0 -poolingType MAX -strideX 1 -strideY 1\" \\\n     -layer \"weka.dl4j.layers.OutputLayer -activation weka.dl4j.activations.ActivationSoftmax -lossFn weka.dl4j.lossfunctions.LossMCXENT\" \\\n     -config \"weka.dl4j.NeuralNetConfiguration -updater weka.dl4j.updater.Adam\" \\\n     -numEpochs 10 \\\n     -t datasets/nominal/mnist.meta.minimal.arff \\\n     -split-percentage 80",
            "title": "Commandline"
        },
        {
            "location": "/examples/classifying-mnist/#java",
            "text": "The same architecture can be built programmatically with the following Java code  // Set up the MLP classifier\nDl4jMlpClassifier clf = new Dl4jMlpClassifier();\nclf.setSeed(1);\nclf.setNumEpochs(10);\n\n\n// Load the arff file\nInstances data = new Instances(new FileReader(\"datasets/nominal/mnist.meta.minimal.arff\"));\ndata.setClassIndex(data.numAttributes() - 1);\n\n\n// Load the image iterator\nImageDataSetIterator imgIter = new ImageDataSetIterator();\nimgIter.setImagesLocation(new File(\"datasets/nominal/mnist-minimal\"));\nimgIter.setHeight(28);\nimgIter.setWidth(28);\nimgIter.setNumChannels(1);\nimgIter.setTrainBatchSize(16);\nclf.setDataSetIterator(imgIter);\n\n\n// Setup the network layers\n// First convolution layer, 8 3x3 filter \nConvolutionLayer convLayer1 = new ConvolutionLayer();\nconvLayer1.setKernelSizeX(3);\nconvLayer1.setKernelSizeY(3);\nconvLayer1.setStrideX(1);\nconvLayer1.setStrideY(1);\nconvLayer1.setActivationFn(new ActivationReLU());\nconvLayer1.setNOut(8);\n\n// First maxpooling layer, 2x2 filter\nSubsamplingLayer poolLayer1 = new SubsamplingLayer();\npoolLayer1.setPoolingType(PoolingType.MAX);\npoolLayer1.setKernelSizeX(2);\npoolLayer1.setKernelSizeY(2);\npoolLayer1.setStrideX(1);\npoolLayer1.setStrideY(1);\n\n// Second convolution layer, 8 3x3 filter\nConvolutionLayer convLayer2 = new ConvolutionLayer();\nconvLayer2.setKernelSizeX(3);\nconvLayer2.setKernelSizeY(3);\nconvLayer2.setStrideX(1);\nconvLayer2.setStrideY(1);\nconvLayer2.setActivationFn(new ActivationReLU());\nconvLayer2.setNOut(8);\n\n// Second maxpooling layer, 2x2 filter\nSubsamplingLayer poolLayer2 = new SubsamplingLayer();\npoolLayer2.setPoolingType(PoolingType.MAX);\npoolLayer2.setKernelSizeX(2);\npoolLayer2.setKernelSizeY(2);\npoolLayer2.setStrideX(1);\npoolLayer2.setStrideY(1);\n\n// Output layer with softmax activation\nOutputLayer outputLayer = new OutputLayer();\noutputLayer.setActivationFn(new ActivationSoftmax());\noutputLayer.setLossFn(new LossMCXENT());\n\n\n// Set up the network configuration\nNeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setUpdater(new Adam());\nclf.setNeuralNetConfiguration(nnc);\n\n\n// Set the layers\nclf.setLayers(new Layer[]{convLayer1, poolLayer1, convLayer2, poolLayer2, outputLayer});\n\n\n// Evaluate the network\nEvaluation eval = new Evaluation(data);\nint numFolds = 10;\neval.crossValidateModel(clf, data, numFolds, new Random(1));\n\nSystem.out.println(\"% Correct = \" + eval.pctCorrect());",
            "title": "Java"
        },
        {
            "location": "/examples/classifying-imdb/",
            "text": "The IMDB Dataset\n\n\nAs of \nai.stanford.edu\n:\n\n\n\n\nThis is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details.\n\n\n\n\nThe full IMDB dataset in the ARFF format can be found \nhere\n.\n\n\nJava RNN\n\n\nThe following code builds a network consisting of an LSTM layer and an RnnOutputLayer, loading imdb reviews and mapping them into a sequence of vectors in the embedding space that is defined by the Google News model. Furthermore, gradient clipping at a value of 1.0 is applied to prevent the network from exploding gradients.\n\n\n// Download e.g the SLIM Google News model from\n// https://github.com/eyaler/word2vec-slim/raw/master/GoogleNews-vectors-negative300-SLIM.bin.gz\nfinal File modelSlim = new File(\"path/to/google/news/model\");\n\n// Setup hyperparameters\nfinal int truncateLength = 80;\nfinal int batchSize = 64;\nfinal int seed = 1;\nfinal int numEpochs = 10;\nfinal int tbpttLength = 20;\nfinal double l2 = 1e-5;\nfinal double gradientThreshold = 1.0;\nfinal double learningRate = 0.02;\n\n// Setup the iterator\nTextEmbeddingInstanceIterator tii = new TextEmbeddingInstanceIterator();\ntii.setWordVectorLocation(modelSlim);\ntii.setTruncateLength(truncateLength);\ntii.setTrainBatchSize(batchSize);\n\n// Initialize the classifier\nRnnSequenceClassifier clf = new RnnSequenceClassifier();\nclf.setSeed(seed);\nclf.setNumEpochs(numEpochs);\nclf.setInstanceIterator(tii);\nclf.settBPTTbackwardLength(tbpttLength);\nclf.settBPTTforwardLength(tbpttLength);\n\n// Define the layers\nLSTM lstm = new LSTM();\nlstm.setNOut(64);\nlstm.setActivationFunction(new ActivationTanH());\n\nRnnOutputLayer rnnOut = new RnnOutputLayer();\n\n// Network config\nNeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setL2(l2);\nnnc.setUseRegularization(true);\nnnc.setGradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue);\nnnc.setGradientNormalizationThreshold(gradientThreshold);\nnnc.setLearningRate(learningRate);\n\n// Config classifier\nclf.setLayers(lstm, rnnOut);\nclf.setNeuralNetConfiguration(nnc);\nInstances data = new Instances(new FileReader(\"src/test/resources/nominal/imdb.arff\"));\ndata.setClassIndex(1);\nclf.buildClassifier(data);\n\n\n\n\nJava CNN\n\n\nBelow is an example building a CNN with two \nConvolutionLayer\n that are automatically merged as described \nhere\n afterwards. \n\n\n\n// Embedding vector size\nint vectorSize = 300;\nint batchSize = 64;\n\n// Initialize iterator\nCnnTextEmbeddingInstanceIterator cnnTextIter = new CnnTextEmbeddingInstanceIterator();\ncnnTextIter.setTrainBatchSize(batchSize);\ncnnTextIter.setWordVectorLocation(DatasetLoader.loadGoogleNewsVectors());\nclf.setInstanceIterator(cnnTextIter);\n\n\n// Define the layers\n// All N convolutional layers will be merged into a single\n// output of depth N (simulates multiple inputs)\nConvolutionLayer conv1 = new ConvolutionLayer();\nconv1.setKernelSize(new int[] {4, vectorSize});\nconv1.setNOut(10);\nconv1.setStride(new int[] {1, vectorSize});\nconv1.setConvolutionMode(ConvolutionMode.Same);\nconv1.setActivationFn(new ActivationReLU());\n\nConvolutionLayer conv2 = new ConvolutionLayer();\nconv2.setKernelSize(new int[] {3, vectorSize});\nconv2.setNOut(10);\nconv2.setStride(new int[] {1, vectorSize});\nconv2.setConvolutionMode(ConvolutionMode.Same);\nconv2.setActivationFn(new ActivationReLU());\n\nGlobalPoolingLayer gpl = new GlobalPoolingLayer();\n\nOutputLayer out = new OutputLayer();\n\n\n// Config classifier\nclf.setLayers(conv1, conv2, gpl, out);\n\n// Get data\nInstances data = new Instances(new FileReader(\"src/test/resources/nominal/imdb.arff\"));\ndata.setClassIndex(1);\n\n// Build model\nclf.buildClassifier(data);",
            "title": "Classifying the IMDB Dataset"
        },
        {
            "location": "/examples/classifying-imdb/#the-imdb-dataset",
            "text": "As of  ai.stanford.edu :   This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details.   The full IMDB dataset in the ARFF format can be found  here .",
            "title": "The IMDB Dataset"
        },
        {
            "location": "/examples/classifying-imdb/#java-rnn",
            "text": "The following code builds a network consisting of an LSTM layer and an RnnOutputLayer, loading imdb reviews and mapping them into a sequence of vectors in the embedding space that is defined by the Google News model. Furthermore, gradient clipping at a value of 1.0 is applied to prevent the network from exploding gradients.  // Download e.g the SLIM Google News model from\n// https://github.com/eyaler/word2vec-slim/raw/master/GoogleNews-vectors-negative300-SLIM.bin.gz\nfinal File modelSlim = new File(\"path/to/google/news/model\");\n\n// Setup hyperparameters\nfinal int truncateLength = 80;\nfinal int batchSize = 64;\nfinal int seed = 1;\nfinal int numEpochs = 10;\nfinal int tbpttLength = 20;\nfinal double l2 = 1e-5;\nfinal double gradientThreshold = 1.0;\nfinal double learningRate = 0.02;\n\n// Setup the iterator\nTextEmbeddingInstanceIterator tii = new TextEmbeddingInstanceIterator();\ntii.setWordVectorLocation(modelSlim);\ntii.setTruncateLength(truncateLength);\ntii.setTrainBatchSize(batchSize);\n\n// Initialize the classifier\nRnnSequenceClassifier clf = new RnnSequenceClassifier();\nclf.setSeed(seed);\nclf.setNumEpochs(numEpochs);\nclf.setInstanceIterator(tii);\nclf.settBPTTbackwardLength(tbpttLength);\nclf.settBPTTforwardLength(tbpttLength);\n\n// Define the layers\nLSTM lstm = new LSTM();\nlstm.setNOut(64);\nlstm.setActivationFunction(new ActivationTanH());\n\nRnnOutputLayer rnnOut = new RnnOutputLayer();\n\n// Network config\nNeuralNetConfiguration nnc = new NeuralNetConfiguration();\nnnc.setL2(l2);\nnnc.setUseRegularization(true);\nnnc.setGradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue);\nnnc.setGradientNormalizationThreshold(gradientThreshold);\nnnc.setLearningRate(learningRate);\n\n// Config classifier\nclf.setLayers(lstm, rnnOut);\nclf.setNeuralNetConfiguration(nnc);\nInstances data = new Instances(new FileReader(\"src/test/resources/nominal/imdb.arff\"));\ndata.setClassIndex(1);\nclf.buildClassifier(data);",
            "title": "Java RNN"
        },
        {
            "location": "/examples/classifying-imdb/#java-cnn",
            "text": "Below is an example building a CNN with two  ConvolutionLayer  that are automatically merged as described  here  afterwards.   \n// Embedding vector size\nint vectorSize = 300;\nint batchSize = 64;\n\n// Initialize iterator\nCnnTextEmbeddingInstanceIterator cnnTextIter = new CnnTextEmbeddingInstanceIterator();\ncnnTextIter.setTrainBatchSize(batchSize);\ncnnTextIter.setWordVectorLocation(DatasetLoader.loadGoogleNewsVectors());\nclf.setInstanceIterator(cnnTextIter);\n\n\n// Define the layers\n// All N convolutional layers will be merged into a single\n// output of depth N (simulates multiple inputs)\nConvolutionLayer conv1 = new ConvolutionLayer();\nconv1.setKernelSize(new int[] {4, vectorSize});\nconv1.setNOut(10);\nconv1.setStride(new int[] {1, vectorSize});\nconv1.setConvolutionMode(ConvolutionMode.Same);\nconv1.setActivationFn(new ActivationReLU());\n\nConvolutionLayer conv2 = new ConvolutionLayer();\nconv2.setKernelSize(new int[] {3, vectorSize});\nconv2.setNOut(10);\nconv2.setStride(new int[] {1, vectorSize});\nconv2.setConvolutionMode(ConvolutionMode.Same);\nconv2.setActivationFn(new ActivationReLU());\n\nGlobalPoolingLayer gpl = new GlobalPoolingLayer();\n\nOutputLayer out = new OutputLayer();\n\n\n// Config classifier\nclf.setLayers(conv1, conv2, gpl, out);\n\n// Get data\nInstances data = new Instances(new FileReader(\"src/test/resources/nominal/imdb.arff\"));\ndata.setClassIndex(1);\n\n// Build model\nclf.buildClassifier(data);",
            "title": "Java CNN"
        },
        {
            "location": "/troubleshooting/",
            "text": "This section shall provide solutions for issues that  may appear.\n\n\n\n\nCUDA: GOMP Version 4.0 not found\n\n\nIssue:\n Starting the \nDl4jMlpClassifier\n while using the GPU version of the package results in something similar to:\n\n\nCaused by: java.lang.UnsatisfiedLinkError: \n    /home/user/.javacpp/cache/nd4j-cuda-8.0-0.9.1-linux-x86_64.jar/org/nd4j/nativeblas/linux-x86_64/libjnind4jcuda.so: \n    /usr/lib/x86_64-linux-gnu/libgomp.so.1: \n    version `GOMP_4.0' not found \n    (required by /home/user/.javacpp/cache/nd4j-cuda-8.0-0.9.1-linux-x86_64.jar/org/nd4j/nativeblas/linux-x86_64/libnd4jcuda.so)\n\n\n\n\n\nThis happens when your system is using a version below 4.9 of the gcc compiler. You can check this with:\n\n\n$ gcc --version\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n\n\n\nTherefore the libgomp.so.1 library is still of version 3.0, while the nd4j backend expects version 4.0.\n\n\nSolution\n: Download the latest version of libgomp for your system and export the following:\n\n\nexport LD_PRELOAD=<PATH-TO-NEW-LIBGOMP.SO>\n\n\n\n\nFor Ubuntu you can get the library \nhere\n, choose your architecture, download and extract the deb-file. For amd64 architectures this would be:\n\n\n$ wget http://security.ubuntu.com/ubuntu/pool/main/g/gcc-5/libgomp1_5.4.0-6ubuntu1~16.04.4_amd64.deb\n$ ar vx libgomp1_5.4.0-6ubuntu1~16.04.4_amd64.deb\n$ tar -xvf data.tar.xz\n\n\n\n\nThis extracts the library to \n./usr/lib/x86_64-linux-gnu/libgomp.so.1\n. Afterward set the \nLD_PRELOAD\n variable to this path as an absolute path and export it as shown above.\n\n\n\n\nCUDA: Failed to allocate X bytes from DEVICE memory\n\n\nIssue:\n Your network architecture or your batch size consumes too much memory.\n\n\nSolution\n: Use a lower batch size, or adjust your Java heap and off-heap limits to your available memory accordingly to the \nofficial Dl4J memory description\n.",
            "title": "Troubleshooting"
        },
        {
            "location": "/troubleshooting/#cuda-gomp-version-40-not-found",
            "text": "Issue:  Starting the  Dl4jMlpClassifier  while using the GPU version of the package results in something similar to:  Caused by: java.lang.UnsatisfiedLinkError: \n    /home/user/.javacpp/cache/nd4j-cuda-8.0-0.9.1-linux-x86_64.jar/org/nd4j/nativeblas/linux-x86_64/libjnind4jcuda.so: \n    /usr/lib/x86_64-linux-gnu/libgomp.so.1: \n    version `GOMP_4.0' not found \n    (required by /home/user/.javacpp/cache/nd4j-cuda-8.0-0.9.1-linux-x86_64.jar/org/nd4j/nativeblas/linux-x86_64/libnd4jcuda.so)  This happens when your system is using a version below 4.9 of the gcc compiler. You can check this with:  $ gcc --version\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  Therefore the libgomp.so.1 library is still of version 3.0, while the nd4j backend expects version 4.0.  Solution : Download the latest version of libgomp for your system and export the following:  export LD_PRELOAD=<PATH-TO-NEW-LIBGOMP.SO>  For Ubuntu you can get the library  here , choose your architecture, download and extract the deb-file. For amd64 architectures this would be:  $ wget http://security.ubuntu.com/ubuntu/pool/main/g/gcc-5/libgomp1_5.4.0-6ubuntu1~16.04.4_amd64.deb\n$ ar vx libgomp1_5.4.0-6ubuntu1~16.04.4_amd64.deb\n$ tar -xvf data.tar.xz  This extracts the library to  ./usr/lib/x86_64-linux-gnu/libgomp.so.1 . Afterward set the  LD_PRELOAD  variable to this path as an absolute path and export it as shown above.",
            "title": "CUDA: GOMP Version 4.0 not found"
        },
        {
            "location": "/troubleshooting/#cuda-failed-to-allocate-x-bytes-from-device-memory",
            "text": "Issue:  Your network architecture or your batch size consumes too much memory.  Solution : Use a lower batch size, or adjust your Java heap and off-heap limits to your available memory accordingly to the  official Dl4J memory description .",
            "title": "CUDA: Failed to allocate X bytes from DEVICE memory"
        }
    ]
}